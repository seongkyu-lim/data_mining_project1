{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_news_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abaafc7062544917ae19a73c70220c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f94e851027ba41fb93bedc8831197793",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f648751b73a344a1bfcc9251818f82f1",
              "IPY_MODEL_afad4d8457d64966bbb4ff4f76491a75"
            ]
          }
        },
        "f94e851027ba41fb93bedc8831197793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f648751b73a344a1bfcc9251818f82f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_455aa9bf8bc040f1a37dd5540454c834",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_764ad953e68f4fb588cb07704c878a6c"
          }
        },
        "afad4d8457d64966bbb4ff4f76491a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c30ab6d0e2ee42a5b35c3c974552252b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 5.29MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ace7c07b4f0243d4b000ebddb0ce0f75"
          }
        },
        "455aa9bf8bc040f1a37dd5540454c834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "764ad953e68f4fb588cb07704c878a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c30ab6d0e2ee42a5b35c3c974552252b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ace7c07b4f0243d4b000ebddb0ce0f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f782358d6ed404e82526234384fe73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a4b42cb188848aebf2b1c05ffc0e8a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb9b8504f84946ad85ff2b5ec9bc09ed",
              "IPY_MODEL_dbdbbceaa74e49a08028e74519313f5e"
            ]
          }
        },
        "5a4b42cb188848aebf2b1c05ffc0e8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb9b8504f84946ad85ff2b5ec9bc09ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fec2784340147a58c5a7ff4a28c0965",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5edbcdafb3c648329a1ac820fd630071"
          }
        },
        "dbdbbceaa74e49a08028e74519313f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b52a84f04e494a3b81815ba67965f2f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 19.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfe2e28797c342e4bd86d61d5023d160"
          }
        },
        "1fec2784340147a58c5a7ff4a28c0965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5edbcdafb3c648329a1ac820fd630071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b52a84f04e494a3b81815ba67965f2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfe2e28797c342e4bd86d61d5023d160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440820427fb244e1a6a3f9509ee9f035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31bd284010fe4fc99dc5a565f661f932",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a0429b3af57c4ba685d50e033c62200e",
              "IPY_MODEL_bb7d72ab051f46f896c7df72996906ec"
            ]
          }
        },
        "31bd284010fe4fc99dc5a565f661f932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0429b3af57c4ba685d50e033c62200e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_432f11c679c44ff0b1c2d26d50d3259b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc85d5934b9440ef89fd4cd345ae491e"
          }
        },
        "bb7d72ab051f46f896c7df72996906ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83f4a6a3fd1540bb86cbe230d68e4e1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:19&lt;00:00, 35.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bfc5bc2aa7248709329627907d259cf"
          }
        },
        "432f11c679c44ff0b1c2d26d50d3259b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc85d5934b9440ef89fd4cd345ae491e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83f4a6a3fd1540bb86cbe230d68e4e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bfc5bc2aa7248709329627907d259cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gatherheart/Classification_With_BERT/blob/main/bert_news_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i45d7E0L8bZ_"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkAHQrj2Vjbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d762686-eff7-48e1-fcb6-a7387b2e3f16"
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=bd04471e2dc6fc04b2d53dfd58f83538ed80bca8eae3a30f6d876f280f963ce7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUsHHOgYHB8M",
        "outputId": "80a71c5b-ad3f-45af-beb4-6eebc199c600"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw4NecgwJylU"
      },
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/hyun_data'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5eBBp2ZoMz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e047224c-d526-4816-973e-d44939e71da8"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec  6 07:00:50 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75dIz2fNWG8F"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_U3uMySBCIV"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Data Load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImBtAkSyTW1r"
      },
      "source": [
        "df = pd.read_csv(BASE_PATH+'/preprocessed_norm.csv', index_col=[0])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz8JzIkdHRSP"
      },
      "source": [
        "labels_csv = pd.read_csv(BASE_PATH+'/labels_dict2.csv', index_col=[0])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "5nPIc5Gh2_zu",
        "outputId": "c2a04bf8-d624-49c2-f5b3-51ad47c1df5d"
      },
      "source": [
        "labels_csv"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문화&gt;방송_연예</th>\n",
              "      <th>국제&gt;중국</th>\n",
              "      <th>사회&gt;사회일반</th>\n",
              "      <th>정치&gt;국회_정당</th>\n",
              "      <th>사회&gt;교육_시험</th>\n",
              "      <th>IT_과학&gt;모바일</th>\n",
              "      <th>정치&gt;행정_자치</th>\n",
              "      <th>사회&gt;사건_사고</th>\n",
              "      <th>문화&gt;문화일반</th>\n",
              "      <th>정치&gt;청와대</th>\n",
              "      <th>사회&gt;여성</th>\n",
              "      <th>국제&gt;유럽_EU</th>\n",
              "      <th>경제&gt;자원</th>\n",
              "      <th>국제&gt;미국_북미</th>\n",
              "      <th>사회&gt;날씨</th>\n",
              "      <th>사회&gt;의료_건강</th>\n",
              "      <th>IT_과학&gt;콘텐츠</th>\n",
              "      <th>경제&gt;증권_증시</th>\n",
              "      <th>정치&gt;선거</th>\n",
              "      <th>국제&gt;일본</th>\n",
              "      <th>사회&gt;미디어</th>\n",
              "      <th>문화&gt;음악</th>\n",
              "      <th>국제&gt;중남미</th>\n",
              "      <th>국제&gt;중동_아프리카</th>\n",
              "      <th>경제&gt;유통</th>\n",
              "      <th>문화&gt;출판</th>\n",
              "      <th>경제&gt;자동차</th>\n",
              "      <th>사회&gt;환경</th>\n",
              "      <th>경제&gt;금융_재테크</th>\n",
              "      <th>사회&gt;장애인</th>\n",
              "      <th>문화&gt;전시_공연</th>\n",
              "      <th>경제&gt;부동산</th>\n",
              "      <th>IT_과학&gt;IT_과학일반</th>\n",
              "      <th>문화&gt;요리_여행</th>\n",
              "      <th>IT_과학&gt;과학</th>\n",
              "      <th>경제&gt;서비스_쇼핑</th>\n",
              "      <th>경제&gt;외환</th>\n",
              "      <th>미분류</th>\n",
              "      <th>문화&gt;미술_건축</th>\n",
              "      <th>문화&gt;생활</th>\n",
              "      <th>경제&gt;경제일반</th>\n",
              "      <th>국제&gt;아시아</th>\n",
              "      <th>정치&gt;정치일반</th>\n",
              "      <th>경제&gt;국제경제</th>\n",
              "      <th>경제&gt;취업_창업</th>\n",
              "      <th>IT_과학&gt;보안</th>\n",
              "      <th>정치&gt;외교</th>\n",
              "      <th>경제&gt;무역</th>\n",
              "      <th>문화&gt;영화</th>\n",
              "      <th>정치&gt;북한</th>\n",
              "      <th>경제&gt;산업_기업</th>\n",
              "      <th>문화&gt;종교</th>\n",
              "      <th>경제&gt;반도체</th>\n",
              "      <th>문화&gt;학술_문화재</th>\n",
              "      <th>사회&gt;노동_복지</th>\n",
              "      <th>국제&gt;국제일반</th>\n",
              "      <th>IT_과학&gt;인터넷_SNS</th>\n",
              "      <th>국제&gt;러시아</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "      <td>51</td>\n",
              "      <td>52</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>55</td>\n",
              "      <td>56</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   문화>방송_연예  국제>중국  사회>사회일반  정치>국회_정당  ...  사회>노동_복지  국제>국제일반  IT_과학>인터넷_SNS  국제>러시아\n",
              "0         0      1        2         3  ...        54       55             56      57\n",
              "\n",
              "[1 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3EotSBxqw3x",
        "outputId": "ce1d5979-5c86-473c-debd-755cad37b9b1"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'title', 'topic', 'keyword', 'tf-idf', 'body', 'label'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "R-XOlwMkrKhA",
        "outputId": "b5b1c5e0-ec93-4ebe-bcb3-7bdaa6245239"
      },
      "source": [
        "df[df.label==0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>keyword</th>\n",
              "      <th>input</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20201128</td>\n",
              "      <td>'온앤오프' 이지아, '데뷔 후 최초' 베일 싸여있던 일상 공개</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>온앤오프,이지아,데뷔,베일,일상,공개,28일,방송,tvN,온앤오프,배우,이지아,반전...</td>\n",
              "      <td>이지아 온앤오프 덕후 한경닷컴 김나경 tvn 은하계 ufo 동작 하나하나 외계인설 ...</td>\n",
              "      <td>28일(토) 방송하는 tvN ’온앤오프‘에서는 배우 이지아의 반전 매력 넘치는 일상...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20201128</td>\n",
              "      <td>'런닝맨' 김소연, '팬심' 폭발시킨 멤버 정체는?</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>런닝맨,김소연,팬심,폭발,멤버,정체,배우,김소연,팬심,고백,29일,방송,SBS,런닝...</td>\n",
              "      <td>김소연 런닝맨 팬심 이상우 멤버들 리액션 반박해 180도 다들 거짓말 펜트하우스 1...</td>\n",
              "      <td>배우 김소연이 수줍은 팬심을 고백한다.\\n오는 29일 오후 방송되는 SBS ‘런닝맨...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>20201128</td>\n",
              "      <td>‘트로트의 민족’ 김소연, 우승 후보→패자부활전 합격할까[M+TV인사이드]</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>트로트,민족,김소연,우승,후보,패자부활전,합격,TV인사이드,트로트,민족,유력,우승,...</td>\n",
              "      <td>트로트 박하명 긴장감 김소연 안성준 시청률 신명근 생존자 패자부활전 장명서 나미애 ...</td>\n",
              "      <td>‘트로트의 민족’ 유력 우승 후보 김소연이 패자부활전에 나선 가운데 그의 생존에 관...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20201128</td>\n",
              "      <td>'아는 형님' 조병규, 즉석 액션부터 성대모사까지 매력 대방출!</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>형님,조병규,즉석,액션,성대모사,매력,대방출,배우,조병규,예능,블루칩,등극,방송,J...</td>\n",
              "      <td>조병규 김세정 눈물 성대모사 유준상 친밀도 만큼 촬영장 웃픈 블루칩 자유자재 전학생...</td>\n",
              "      <td>배우 조병규가 넘치는 끼로 예능 블루칩에 등극했다.\\n \\n28일 방송되는 JTBC...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>20201128</td>\n",
              "      <td>‘온앤오프’ 이지아 “UFO 출몰 지역을 간 적도 있다”</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>온앤오프,이지아,UFO,출몰,지역,28일,방송,tvN,온앤오프,배우,이지아,반전,매...</td>\n",
              "      <td>이지아 온앤오프 덕후 ufo tvn 동작 하나하나 은하계 외계인설 싱어송라이터 놀라...</td>\n",
              "      <td>[헤럴드경제 = 서병기 선임기자]28일(토) 밤 방송되는 tvN ’온앤오프‘에서는 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19069</th>\n",
              "      <td>20201201</td>\n",
              "      <td>영화보며 시간 여행 자연 힐링 독서하며 언택트 송년</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>영화,여행,자연,힐링,독서,언택트,송년,연말,영화,리틀,포레스트,Little,개봉,...</td>\n",
              "      <td>구멍가게 일본 순천만 미국 곽재구 루나나 해남 목포 원스 혜원 보이저 시간여행 드루...</td>\n",
              "      <td>[연말에 보면 좋은 영화]\\n▲리틀 포레스트(Little Forest /감독 임순례...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19304</th>\n",
              "      <td>20201201</td>\n",
              "      <td>[종합] 아이랜드 통해 데뷔한 '엔하이픈' \"7명 전원이 센터급 비주얼\"  연말 신...</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>아이랜드,데뷔,엔하이픈,전원,센터,비주얼,연말,신인상,사진,빌리프랩,제공,빅히트엔터...</td>\n",
              "      <td>엔하이픈 아이랜드 빅히트 니키 희승 제이크 제이 타이틀곡 성훈 7명 신인상 팬들 방...</td>\n",
              "      <td>[사진= 빌리프랩 제공] \\n  \\n \\n 빅히트엔터테인먼트와 Mnet의 프로젝트 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19581</th>\n",
              "      <td>20201130</td>\n",
              "      <td>[이웃사랑] 뇌병변에 유방암까지 온 아내, 홀로 고군분투 중인 남편</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>뇌병변,유방암,아내,고군분투,남편,결혼식,뇌병변,장애,남편,4년,병간호,유방암,생활...</td>\n",
              "      <td>주희 영석 결혼식 예주 유방암 중국집 대구은행 병간호 핸드폰 일자리 생활비 매일신문...</td>\n",
              "      <td>지난 27일 달서구 감삼동의 한 주택 2층. 쿵쾅쿵쾅 계단 위로 한 여자아이가 급히...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19598</th>\n",
              "      <td>20201130</td>\n",
              "      <td>전효성 다이어트 “3개월만에 허리 26인치→23.5인치”</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>3개월,전효,다이어트,허리,인치,23.5인치,가수,전효,다이어트,영상,공개,화제,전...</td>\n",
              "      <td>전효성 전효 3개월 다이어터 필라테스 배달음식 필요성 유튜브 장장 2개월 식이요법 ...</td>\n",
              "      <td>가수 전효성이 다이어트 영상을 공개해 화제다.\\n\\n\\n\\n전효성이 30일 오후 자...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19930</th>\n",
              "      <td>20201130</td>\n",
              "      <td>아산시 ‘은빛 숲해설’ 프로그램, 요양기관 어르신에 활력 제공</td>\n",
              "      <td>문화&gt;방송_연예</td>\n",
              "      <td>숲해설,아산시,은빛,프로그램,요양,기관,어르신,활력,제공,아산시,시장,오세현,코로나...</td>\n",
              "      <td>요양기관 어르신들 코로나19 비대면 숲해설 외부인 복지사 아산시 자연물 아산 영상콘...</td>\n",
              "      <td>아산시(시장 오세현)가 코로나19 장기화로 외부인과의 접촉이 제한된 관내 13개 요...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2201 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... label\n",
              "8      20201128  ...     0\n",
              "10     20201128  ...     0\n",
              "15     20201128  ...     0\n",
              "21     20201128  ...     0\n",
              "67     20201128  ...     0\n",
              "...         ...  ...   ...\n",
              "19069  20201201  ...     0\n",
              "19304  20201201  ...     0\n",
              "19581  20201130  ...     0\n",
              "19598  20201130  ...     0\n",
              "19930  20201130  ...     0\n",
              "\n",
              "[2201 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "Rozn-qYIhYq_",
        "outputId": "d16d13e2-f74a-4c0e-9c5d-6657b827cb3b"
      },
      "source": [
        "df[df['label']==10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>keyword</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>20201128</td>\n",
              "      <td>옥천군, 여성폭력 추방 캠페인 실시</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>옥천군,캠페인,여성,폭력,추방,캠페인,충북일보,옥천군,추방주간,여성,폭력,추방,주간...</td>\n",
              "      <td>여성폭력,성매매,성폭력,전단지,추방기간,옥천군여성단체협의회원,옥천여자중학교,옥천군,...</td>\n",
              "      <td>［충북일보］ 옥천군은 27일 '여성폭력 추방주간'을 맞아 옥천여자중학교 앞에서 옥천...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>20201128</td>\n",
              "      <td>\"사지 마비된 동생, 사과 없는 가해자 엄중 처벌해달라\" 피해자 가족 호소</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>마비,동생,사과,가해자,처벌,호소,피해자,가족,경남,진주,발생,칼치기,사고,버스,여...</td>\n",
              "      <td>가해자,청원인,피해자,청원,이종기,변호사,진주지원,공소장,고등학교,특례법,졸업식,진...</td>\n",
              "      <td>2019년 12월 경남 진주에서 발생한 '칼치기 사고'로 버스에 타고 있던 고등학교...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>20201128</td>\n",
              "      <td>경남 창원 단란주점 관련 4명 진주 이통장 2명 등 13명 추가 확진</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>단란주점,4명,경남,창원,단란주점,진주,통장,확진,추가,경남,신종,코로나바이러스,감...</td>\n",
              "      <td>확진자,50대,진주,창원,경남,사천,단란주점,60대,김해,2명,4명,접촉자,감염경로...</td>\n",
              "      <td>[아시아경제 영남취재본부 주철인 기자] 경남의 신종 코로나바이러스감염증(코로나19)...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>20201128</td>\n",
              "      <td>\"뺨을 베어갈 듯\" 칼바람 막아줄 수분 신상템</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>칼바람,수분,기온,칼바람,피부,건조,겨울철,제품,피부,장벽,케어,겨울,바람,피부,보...</td>\n",
              "      <td>저자극,마이크로바이옴,고보습,화장품,활성화,유익균,제니피끄,흡수력,비건,보습력,스킨...</td>\n",
              "      <td>[아시아경제 조유진 기자] 급격히 떨어진 기온과 칼바람으로 피부가 건조해지기 쉬운 ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>20201128</td>\n",
              "      <td>비혼 임신, 법과 현실의 간극</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>비혼,임신,현실,간극,사유리,방송인,후지타,비혼출산,한국사회,파장,한국,결혼,사람,...</td>\n",
              "      <td>기증자,비혼여성,비혼,생명윤리법,시험관,윤리지침,난임,인공수정,난임부부,한국,나영정...</td>\n",
              "      <td>방송인 후지타 사유리의 비혼출산은 한국사회에 적잖은 파장을 불러왔다. “한국에서는 ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19191</th>\n",
              "      <td>20201201</td>\n",
              "      <td>대한적십자사봉사회 괴산지구협의회, 희망 꾸러미 키트 나눔 펼쳐</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>대한적십자사봉,사회,괴산지구협의회,키트,희망,꾸러미,대한적십자사봉,사회,괴산,지구,...</td>\n",
              "      <td>코로나19,괴산,괴산지구협의회,키트,김영,취약계층,10여,최준환,적십자봉사회,봉사활...</td>\n",
              "      <td>[충청투데이 김영 기자] 대한적십자사봉사회 괴산지구협의회가 연탄나눔 봉사활동에 이어...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19316</th>\n",
              "      <td>20201201</td>\n",
              "      <td>코로나 블루 극단적 선택 여성 급증 스마트폰 대신 햇빛 보세요</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>코로나,블루,극단,선택,여성,급증,스마트폰,햇빛,운동,도움,우울증,예방,고위험군,정...</td>\n",
              "      <td>우울증,코로나,50대,재택근무,부산,스마트폰,사망자,생활비,관련자,정신과,좌절감,자...</td>\n",
              "      <td>- 정부 차원 고위험군 서둘러 발굴\\n- 상담 제공 등 안전망 관리해야\\n\\n올들어...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19423</th>\n",
              "      <td>20201201</td>\n",
              "      <td>코로나 연말연시 모이거나 미루거나 멈추거나</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>코로나,연말연시,풍경,도민,연말맞이,감염증,신종,코로나바이러스,코로나19,재확산,연...</td>\n",
              "      <td>코로나19,창원,파티룸,친구들,확진자,도민들,연말맞이,2단계,대유행,마산,연말연시,...</td>\n",
              "      <td>신종 코로나바이러스 감염증(코로나19)이 재확산되는 가운데 연말연시를 맞는 도민들의...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19537</th>\n",
              "      <td>20201201</td>\n",
              "      <td>화성시 12월부터 사회적 거리두기 단계별 일회용품 사용규제 시행</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>화성시,사회,거리,단계,일회용품,사용,규제,시행,화성시,12월,사회,거리,사용규제,...</td>\n",
              "      <td>일회용품,다회용,사용규제,과태료,코로나19,시행령,화성시,그동안,식품접객업소,활용법...</td>\n",
              "      <td>화성시는 12월부터 사회적 거리두기 단계별 일회용품 사용규제를 시행한다고 30일 밝...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19578</th>\n",
              "      <td>20201130</td>\n",
              "      <td>속초 요양원에서 코로나19 확진자 발생 100세 입소자</td>\n",
              "      <td>사회&gt;여성</td>\n",
              "      <td>속초,요양원,발생,코로나19,확진자,100세,입소자,속초,지난달,A씨,여성,코로나1...</td>\n",
              "      <td>코로나19,요양원,확진자,100세,코호트,a씨,이동동선,입소자,박주석,여성,지역,환...</td>\n",
              "      <td>[강원도민일보 박주석 기자] 지난달 30일 속초에서 100세 여성 A씨가 코로나19...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1068 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... label\n",
              "61     20201128  ...    10\n",
              "103    20201128  ...    10\n",
              "197    20201128  ...    10\n",
              "320    20201128  ...    10\n",
              "397    20201128  ...    10\n",
              "...         ...  ...   ...\n",
              "19191  20201201  ...    10\n",
              "19316  20201201  ...    10\n",
              "19423  20201201  ...    10\n",
              "19537  20201201  ...    10\n",
              "19578  20201130  ...    10\n",
              "\n",
              "[1068 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKceTBZaIDvC",
        "outputId": "08645757-fde5-49b8-f8f2-d676a4474ce0"
      },
      "source": [
        "print(set(df['label']))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWM6a5ScIPEI"
      },
      "source": [
        "NUM_LABELS = max(set(df['label'])) + 1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFy6QpR_IT1Q",
        "outputId": "d5cff2e1-f81f-4a0d-b062-879dcc516393"
      },
      "source": [
        "NUM_LABELS"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4796eNIIKJ0"
      },
      "source": [
        "text_to_label = dict(labels_csv)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUPKFkHeHmOx",
        "outputId": "9625ee61-8b66-4fb5-e64d-cf2685a7b861"
      },
      "source": [
        "int(text_to_label['IT_과학>IT_과학일반'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jsFUJV-IhrA"
      },
      "source": [
        "label_to_text = {}\n",
        "for label in text_to_label:\n",
        "    label_to_text[int(text_to_label[label])] = label"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcEcNAGjHfwg",
        "outputId": "708d7ef7-05f6-4096-94d9-270ed630f927"
      },
      "source": [
        "label_to_text"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '문화>방송_연예',\n",
              " 1: '국제>중국',\n",
              " 2: '사회>사회일반',\n",
              " 3: '정치>국회_정당',\n",
              " 4: '사회>교육_시험',\n",
              " 5: 'IT_과학>모바일',\n",
              " 6: '정치>행정_자치',\n",
              " 7: '사회>사건_사고',\n",
              " 8: '문화>문화일반',\n",
              " 9: '정치>청와대',\n",
              " 10: '사회>여성',\n",
              " 11: '국제>유럽_EU',\n",
              " 12: '경제>자원',\n",
              " 13: '국제>미국_북미',\n",
              " 14: '사회>날씨',\n",
              " 15: '사회>의료_건강',\n",
              " 16: 'IT_과학>콘텐츠',\n",
              " 17: '경제>증권_증시',\n",
              " 18: '정치>선거',\n",
              " 19: '국제>일본',\n",
              " 20: '사회>미디어',\n",
              " 21: '문화>음악',\n",
              " 22: '국제>중남미',\n",
              " 23: '국제>중동_아프리카',\n",
              " 24: '경제>유통',\n",
              " 25: '문화>출판',\n",
              " 26: '경제>자동차',\n",
              " 27: '사회>환경',\n",
              " 28: '경제>금융_재테크',\n",
              " 29: '사회>장애인',\n",
              " 30: '문화>전시_공연',\n",
              " 31: '경제>부동산',\n",
              " 32: 'IT_과학>IT_과학일반',\n",
              " 33: '문화>요리_여행',\n",
              " 34: 'IT_과학>과학',\n",
              " 35: '경제>서비스_쇼핑',\n",
              " 36: '경제>외환',\n",
              " 37: '미분류',\n",
              " 38: '문화>미술_건축',\n",
              " 39: '문화>생활',\n",
              " 40: '경제>경제일반',\n",
              " 41: '국제>아시아',\n",
              " 42: '정치>정치일반',\n",
              " 43: '경제>국제경제',\n",
              " 44: '경제>취업_창업',\n",
              " 45: 'IT_과학>보안',\n",
              " 46: '정치>외교',\n",
              " 47: '경제>무역',\n",
              " 48: '문화>영화',\n",
              " 49: '정치>북한',\n",
              " 50: '경제>산업_기업',\n",
              " 51: '문화>종교',\n",
              " 52: '경제>반도체',\n",
              " 53: '문화>학술_문화재',\n",
              " 54: '사회>노동_복지',\n",
              " 55: '국제>국제일반',\n",
              " 56: 'IT_과학>인터넷_SNS',\n",
              " 57: '국제>러시아'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrmgTPCerl1b"
      },
      "source": [
        "df = df.rename(columns={'특성추출(가중치순 상위 50개)':'input'})"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LPEdb2tWfIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730506a5-8e6c-4f5b-8bf0-0e46b170de37"
      },
      "source": [
        "train, test = train, test = train_test_split(df, test_size=0.2)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38783, 7)\n",
            "(9696, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tejY9ZhABYWl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "1a7efacb-4408-401d-9a49-b90ec800c9b0"
      },
      "source": [
        "# 훈련셋의 앞부분 출력\n",
        "train.head(10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>keyword</th>\n",
              "      <th>input</th>\n",
              "      <th>body</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4370</th>\n",
              "      <td>20201204</td>\n",
              "      <td>수능 시험 뒤 고3 수험생 등 학교 방역은?</td>\n",
              "      <td>사회&gt;교육_시험</td>\n",
              "      <td>수능,시험,수험,학교,방역,앵커,전북,2천,학년도,대입수학능력시험,순조,교육당국,수...</td>\n",
              "      <td>수험생 전북교육청 감독관 코로나19 고사장 오중호 노래방 영화관 촬영기자 다중이용시...</td>\n",
              "      <td>[KBS 전주]\\n [앵커]\\n\\n오늘 전북에서도 2천21학년도 대입수학능력시험이 ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11312</th>\n",
              "      <td>20201120</td>\n",
              "      <td>한국능률협회컨설팅, ‘2021사업계획수립’ 결정지을 온라인 강의 론칭</td>\n",
              "      <td>경제&gt;경제일반</td>\n",
              "      <td>한국능률협회컨설팅,2021사업,계획수립,론칭,온라인,강의,한국능률협회컨설팅,KMAC...</td>\n",
              "      <td>실리콘밸리 온라인 미국 론칭 부회장 김종립 한국능률협회컨설팅 kmac 문의전화 홈페...</td>\n",
              "      <td>한국능률협회컨설팅(이하 KMAC, 대표이사 부회장 김종립)이 미국 실리콘밸리 혁신기...</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>20201128</td>\n",
              "      <td>[속보] 코로나19 사망자 어제 6명 늘어 총 522명</td>\n",
              "      <td>국제&gt;아시아</td>\n",
              "      <td>코로나19,사망자,522명,속보,코로나19,코로나19,사망자,522명</td>\n",
              "      <td>코로나19 사망자 속보</td>\n",
              "      <td>[속보] 코로나19 어제 사망자 6명 늘어 총 522명 (끝) \\n \\n oh@he...</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6039</th>\n",
              "      <td>20201121</td>\n",
              "      <td>[코로나19] 일본, 사상 최초 일일 확진자 2560명...도쿄서만 539명 나와</td>\n",
              "      <td>국제&gt;일본</td>\n",
              "      <td>일본,사상,2560명,일일,확진자,도쿄서,539명,고투,트래블,Travel,불가피,...</td>\n",
              "      <td>일본 확진자 코로나19 이트 나흘 행인들 사망자 긴자 번화가 횡단보도 도쿄도 nhk...</td>\n",
              "      <td>일본 도쿄의 번화가인 긴자 거리에서 마스크를 쓴 행인들이 횡단보도를 건너는 모습. ...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15386</th>\n",
              "      <td>20201201</td>\n",
              "      <td>OECD “한국 올해 성장률 -1.1% 회원국 중 최소 하락”</td>\n",
              "      <td>경제&gt;국제경제</td>\n",
              "      <td>OECD,한국,성장,1.1%,회원국,최소,하락,경제협력개발기구,OECD,전망치,한국...</td>\n",
              "      <td>오이시디 회원국 한국 코로나19 성장률 로렌스 중국 연평균 전망치 하향조정 서비스업...</td>\n",
              "      <td>경제협력개발기구(OECD)가 올해 한국 경제성장률 전망치를 지난 9월 -1.0%에서...</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4009</th>\n",
              "      <td>20201127</td>\n",
              "      <td>[속보] 어제 569명 확진, 이틀 연속 500명대</td>\n",
              "      <td>사회&gt;사회일반</td>\n",
              "      <td>확진,500명대,이틀,연속,명대,26일,신규,코로나,확진자,569명,집계,중앙방역대...</td>\n",
              "      <td>확진자 var 2단계 중앙재난안전대책본부 수도권 서울 인천 코로나19 일주일 코로나...</td>\n",
              "      <td>어제(26일) 국내 신규 코로나 확진자는 569명으로 집계됐다. 중앙방역대책본부는 ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7052</th>\n",
              "      <td>20201127</td>\n",
              "      <td>文대통령 \"수소차 등 미래차, 탄소중립 선도산업으로 육성\"</td>\n",
              "      <td>정치&gt;청와대</td>\n",
              "      <td>대통령,수소차,미래차,탄소,중립,선도,산업,육성,문재인,대통령,청와대,2050탄소,...</td>\n",
              "      <td>미래차 저탄소 수소차 청와대 일자리 기술혁신 충전소 제조업 2050탄소 민간기업 산...</td>\n",
              "      <td>[머니투데이 정진우 기자] [[the300]]\\n\\n \\n\\n\\n문재인 대통령이 2...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10796</th>\n",
              "      <td>20201120</td>\n",
              "      <td>서울시교육청 “내일 중등 임용시험 예정대로 실시  확진자 응시 불가”</td>\n",
              "      <td>사회&gt;교육_시험</td>\n",
              "      <td>서울시교육청,불가,확진자,응시,노량진,교사,임용,시험,학원,코로나19,집단,감염,발...</td>\n",
              "      <td>서울 임용시험 코로나19 확진자 노량진 교육청 시험실 관계자 선정경쟁시험 자가격리자...</td>\n",
              "      <td>노량진 교사 임용시험 학원에서 코로나19 집단감염이 발생한 것과 관련해 교육당국은 ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10394</th>\n",
              "      <td>20191128</td>\n",
              "      <td>[자막뉴스] '한국에 양보' 비난 피하려고? 또 억지 주장 펴는 일본</td>\n",
              "      <td>국제&gt;일본</td>\n",
              "      <td>한국,양보,비난,억지,주장,일본,22일,청와대,지소미아,조건부,종료,연기,5분,일본...</td>\n",
              "      <td>일본 지소미아 한국 요이치 관리부장 그간 사이토 청와대 외무상 조건부 자막뉴스 영상...</td>\n",
              "      <td>지난 22일 오후 6시 청와대가 지소미아 조건부 종료 연기를 발표하자 5분쯤 뒤 일...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5052</th>\n",
              "      <td>20201122</td>\n",
              "      <td>(속보) 익산 또 추가 확진 3명... 닷새간 31명</td>\n",
              "      <td>사회&gt;사회일반</td>\n",
              "      <td>속보,익산,3명,추가,확진,닷새,익산지역,3명,코로나19,확진자,추가,발생,전북18...</td>\n",
              "      <td>익산 3명 닷새간 확진자 익산시 전북181번 전북 원광대병원 익산21번 간호사 원광...</td>\n",
              "      <td>익산지역에서 또다시 3명의 코로나19 확진자가 추가 발생했다. \\n\\n전북181번(...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           date  ... label\n",
              "4370   20201204  ...     4\n",
              "11312  20201120  ...    40\n",
              "480    20201128  ...    41\n",
              "6039   20201121  ...    19\n",
              "15386  20201201  ...    43\n",
              "4009   20201127  ...     2\n",
              "7052   20201127  ...     9\n",
              "10796  20201120  ...     4\n",
              "10394  20191128  ...    19\n",
              "5052   20201122  ...     2\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgjMzosCDD35"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Preprocessing - TRAINING SET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GoESQ0jbybJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6699082-7aa3-4a35-fe78-42fd7dfef428"
      },
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = train['input']\n",
        "sentences[:10]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4370     수험생 전북교육청 감독관 코로나19 고사장 오중호 노래방 영화관 촬영기자 다중이용시...\n",
              "11312    실리콘밸리 온라인 미국 론칭 부회장 김종립 한국능률협회컨설팅 kmac 문의전화 홈페...\n",
              "480                                           코로나19 사망자 속보\n",
              "6039     일본 확진자 코로나19 이트 나흘 행인들 사망자 긴자 번화가 횡단보도 도쿄도 nhk...\n",
              "15386    오이시디 회원국 한국 코로나19 성장률 로렌스 중국 연평균 전망치 하향조정 서비스업...\n",
              "4009     확진자 var 2단계 중앙재난안전대책본부 수도권 서울 인천 코로나19 일주일 코로나...\n",
              "7052     미래차 저탄소 수소차 청와대 일자리 기술혁신 충전소 제조업 2050탄소 민간기업 산...\n",
              "10796    서울 임용시험 코로나19 확진자 노량진 교육청 시험실 관계자 선정경쟁시험 자가격리자...\n",
              "10394    일본 지소미아 한국 요이치 관리부장 그간 사이토 청와대 외무상 조건부 자막뉴스 영상...\n",
              "5052     익산 3명 닷새간 확진자 익산시 전북181번 전북 원광대병원 익산21번 간호사 원광...\n",
              "Name: input, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KkJZvhccRUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69490511-2f19-458d-c97f-ea93950b3569"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 수험생 전북교육청 감독관 코로나19 고사장 오중호 노래방 영화관 촬영기자 다중이용시설 가림막 고등학교 2천 학부모 학년도 전북 대입수학능력시험 유튜브 시험장 지자체 안전사고 정영수 설명회 김진호 교육당국 함산 시험실 [SEP]',\n",
              " '[CLS] 실리콘밸리 온라인 미국 론칭 부회장 김종립 한국능률협회컨설팅 kmac 문의전화 홈페이지 한국능률협회 트랜스포메이션 소비재 거시적 2021사업 소매업 100여 리테일 계획수립 [SEP]',\n",
              " '[CLS] 코로나19 사망자 속보 [SEP]',\n",
              " '[CLS] 일본 확진자 코로나19 이트 나흘 행인들 사망자 긴자 번화가 횡단보도 도쿄도 nhk 매입가격 전문가 상품권 광역자치단체 [SEP]',\n",
              " '[CLS] 오이시디 회원국 한국 코로나19 성장률 로렌스 중국 연평균 전망치 하향조정 서비스업 반도체 비정규직 재확산 경제학자 경제활동 oecd 일자리 미국 20개국 전환점 경제전망 [SEP]',\n",
              " '[CLS] 확진자 var 2단계 중앙재난안전대책본부 수도권 서울 인천 코로나19 일주일 코로나 script document id dist js https 대유행 판가름 전문가 정세균 [SEP]',\n",
              " '[CLS] 미래차 저탄소 수소차 청와대 일자리 기술혁신 충전소 제조업 2050탄소 민간기업 산업생태계 기관차 문재인 전기차 산업 전환 지원 대통령 중심 노력 탄소 중립 육성 집중 전략 회의 확대 기업 관심 주재 보급 민간 혁신 확충 각별 생산 총력 대대적 [SEP]',\n",
              " '[CLS] 서울 임용시험 코로나19 확진자 노량진 교육청 시험실 관계자 선정경쟁시험 자가격리자 서울시교육청 지원자 신청서 집단감염 동작구 200여명 [SEP]',\n",
              " '[CLS] 일본 지소미아 한국 요이치 관리부장 그간 사이토 청와대 외무상 조건부 자막뉴스 영상편집 황보연 기자들 취재기자 미국 아베 삼척동자 가지야마 모테기 도쿄 [SEP]',\n",
              " '[CLS] 익산 3명 닷새간 확진자 익산시 전북181번 전북 원광대병원 익산21번 간호사 원광대학교병원 익산지역 1명 코로나19 80대 20대 거주 확진 추가 퇴원 나머지 닷새 판정 동선 당국 보건 환자 발생 지역 조사 속보 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hBblIVQcXJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be24277b-5d9a-4449-d5fa-c36803c5ef4c"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = train['label'].values\n",
        "labels"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4, 40, 41, ..., 49, 13, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwEplfDvcnZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "abaafc7062544917ae19a73c70220c1d",
            "f94e851027ba41fb93bedc8831197793",
            "f648751b73a344a1bfcc9251818f82f1",
            "afad4d8457d64966bbb4ff4f76491a75",
            "455aa9bf8bc040f1a37dd5540454c834",
            "764ad953e68f4fb588cb07704c878a6c",
            "c30ab6d0e2ee42a5b35c3c974552252b",
            "ace7c07b4f0243d4b000ebddb0ce0f75"
          ]
        },
        "outputId": "303728eb-62a3-43e7-cb12-323589ecbe11"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abaafc7062544917ae19a73c70220c1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CLS] 수험생 전북교육청 감독관 코로나19 고사장 오중호 노래방 영화관 촬영기자 다중이용시설 가림막 고등학교 2천 학부모 학년도 전북 대입수학능력시험 유튜브 시험장 지자체 안전사고 정영수 설명회 김진호 교육당국 함산 시험실 [SEP]\n",
            "['[CLS]', '수', '##험', '##생', '전', '##북', '##교', '##육', '##청', '감독', '##관', '코', '##로', '##나', '##19', '고', '##사', '##장', '오', '##중', '##호', '노래', '##방', '영화', '##관', '촬', '##영', '##기', '##자', '다', '##중', '##이', '##용', '##시', '##설', '가', '##림', '##막', '고', '##등학교', '2', '##천', '학', '##부', '##모', '학', '##년', '##도', '전', '##북', '대', '##입', '##수', '##학', '##능', '##력', '##시', '##험', '유', '##튜', '##브', '시', '##험', '##장', '지', '##자', '##체', '안', '##전', '##사', '##고', '정', '##영', '##수', '설', '##명', '##회', '김', '##진', '##호', '교', '##육', '##당', '##국', '함', '##산', '시', '##험', '##실', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QQf6JsMhiVWW",
        "outputId": "db12c3bb-066e-4433-a7ae-d52f4d645a57"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(list(map(len, tokenized_texts)))\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ76KiP_dLn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d18f6d-9fb9-464f-d7b3-19fb187bc337"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9460,  86834,  24017,   9665,  82512,  25242,  83811,\n",
              "        40311,  81571,  20595,   9812,  11261,  16439,  54055,   8888,\n",
              "        12945,  13890,   9580,  41693,  20309,  99706,  42337,  42428,\n",
              "        20595,   9763,  30858,  12310,  13764,   9056,  41693,  10739,\n",
              "        24974,  14040,  31928,   8843,  67527, 118907,   8888,  55511,\n",
              "          123,  38631,   9953,  14646,  39420,   9953,  10954,  12092,\n",
              "         9665,  82512,   9069,  58303,  15891,  23321,  74986,  28143,\n",
              "        14040,  86834,   9625, 119368,  52015,   9485,  86834,  13890,\n",
              "         9706,  13764,  29683,   9521,  16617,  12945,  11664,   9670,\n",
              "        30858,  15891,   9429,  16758,  14863,   8935,  18623,  20309,\n",
              "         8907,  83811,  21928,  20479,   9956,  21386,   9485,  86834,\n",
              "        31503,    102,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y10yOyYFrj90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abed0545-eecd-4d92-a38e-cf9d9a4a523b"
      },
      "source": [
        "print(tokenizer.convert_ids_to_tokens(input_ids[0]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', '수', '##험', '##생', '전', '##북', '##교', '##육', '##청', '감독', '##관', '코', '##로', '##나', '##19', '고', '##사', '##장', '오', '##중', '##호', '노래', '##방', '영화', '##관', '촬', '##영', '##기', '##자', '다', '##중', '##이', '##용', '##시', '##설', '가', '##림', '##막', '고', '##등학교', '2', '##천', '학', '##부', '##모', '학', '##년', '##도', '전', '##북', '대', '##입', '##수', '##학', '##능', '##력', '##시', '##험', '유', '##튜', '##브', '시', '##험', '##장', '지', '##자', '##체', '안', '##전', '##사', '##고', '정', '##영', '##수', '설', '##명', '##회', '김', '##진', '##호', '교', '##육', '##당', '##국', '함', '##산', '시', '##험', '##실', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKfL8SotdVaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1702806-8bc2-4860-df45-3e9b78f15dab"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f5Vq3-7eNKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc1b8f5-66c4-4c0e-b884-2776500c5efc"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=2020, \n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2020,\n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   8903,  16323,   9994,  18623,  13764,   9022,  44321,  18623,\n",
            "          9812,  11261,  16439,  54055,  48253,   8900,  21611,  13764,   9644,\n",
            "         24974,  11664,  14040,   9460,  86834,  24017,   8907,  83811,  14646,\n",
            "          9644,  24974,  14040,  86834,   9460,  47181,  24017,    122,  16758,\n",
            "          9751,  12638,  14423,   9989, 119391,  44359,   9639,  21386,    102,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "tensor([   101,   9812,  11261,  16439,  54055,   9994,  18623,  13764,   9670,\n",
            "         24982,  77692,   9659, 119342,  50248,  32537,   9994,  21386,  24982,\n",
            "          9706,  13764,  29683,  68495,   9764,  22333,  18227,   9637,  71013,\n",
            "        119230,  14871,   9069,  20479,  36553, 105462,  18227,  51175,   9708,\n",
            "         24989, 118625,  12945,   8909,  36553,  27023,   9358,  14646,  13890,\n",
            "          9328,  23160,  15891, 119283,   9641,  14871,  24017, 119446,   9069,\n",
            "         17196,   9812,  11261,  16439,   9641,  16323,  18392,  18784,   9064,\n",
            "         18227,  25934,   9460,  86834,  24017,   9069,  20479,  36553,    102,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(15)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3vlyUJuVRo5"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqUHx51dffp"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Preprocessing - TEST SET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgrsNuArd4pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3356e27b-9b2a-42eb-a42a-bdf084ede26d"
      },
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = test['input']\n",
        "sentences[:10]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18542    rcep 중소기업 fta 인지도 중기중앙회 경쟁력 지원정책 온라인 일본 김태환 전시...\n",
              "9971     병원장 서울아산병원장 박성욱 남기호 박승일 아산의료원장 정몽준 아산 이사장 아산사회...\n",
              "18031    합창단 동아시아 인천 합창제 중국 한국 인천시 외국인 코로나19 국제합창제 서구문화...\n",
              "732      생활관리사 간담회 관리사 독거노인 소하노인종합복지관 광명시 박승원 병원동 병원동행 ...\n",
              "4791     최수종 커플룩 인스타 해시태그 최윤서씨 누리꾼 다정 인스타그램 최윤서 뒷모습 시간들...\n",
              "16790    학생들 임성호 고사장 코로나19 재수생 가림막 난이도 ytn 순발력 코로나바이러스 ...\n",
              "2640     생존자 자살생존자 한국 자살자 유가족 외도 사람들 상처들 황웃는돌씨 통계청 황웃는돌...\n",
              "4658     민원인 공직자 박성일 완주 서원대학교 완주군 정태연 친절도 서비스학 체감친절도 주민...\n",
              "8959     온젠티스 파킨슨병 치료제 레보도파 유럽 비알 파킨슨 김정훈 중추신경계 동작 운동동요...\n",
              "11351     서울 동작구 학년도 숭실대학교 고사장 시험 논술 신분 대학 수학 수험 능력 확인 마스크\n",
              "Name: input, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtz3QZt9d4pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99eadc56-b635-4357-891d-e4e3db0e244e"
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] rcep 중소기업 fta 인지도 중기중앙회 경쟁력 지원정책 온라인 일본 김태환 전시회 활용방안 정작 [SEP]',\n",
              " '[CLS] 병원장 서울아산병원장 박성욱 남기호 박승일 아산의료원장 정몽준 아산 이사장 아산사회복지재단 홍천아산병원장 홍천아산 부원장 박성욱씨 서울아산 진료 임명 원장 임기 의료 사진 부장 [SEP]',\n",
              " '[CLS] 합창단 동아시아 인천 합창제 중국 한국 인천시 외국인 코로나19 국제합창제 서구문화회관 인천서구문화회관 동아시아인 대사관 경기일보 음대교수 베트남 인천관광공사 입상팀 전통악기 협회장 합창지휘자 필리핀 자신들 관계자 협회장상 전통민요 전통의상 관광부 음악성 자부심 자유곡 주한중국문화원 일본 [SEP]',\n",
              " '[CLS] 생활관리사 간담회 관리사 독거노인 소하노인종합복지관 광명시 박승원 병원동 병원동행 말벗서비스 어르신들 주년 일상생활 시장님 안부확인 말벗 만65세 광명 기본서비스 고독사 1천 생활관리들 생활관리사들 노인돌 시간date 노인맞춤 서비스 노인 생활 지원 시장 확대 [SEP]',\n",
              " '[CLS] 최수종 커플룩 인스타 해시태그 최윤서씨 누리꾼 다정 인스타그램 최윤서 뒷모습 시간들 하희라 sns 모습 산책 결혼 자신 감사 가을 시간 그램 사랑 통로 누리 공개 슬하 부녀 분위기 아빠 축복 팔짱 연인 사진 영상 반응 게재 일상 공유 [SEP]',\n",
              " '[CLS] 학생들 임성호 고사장 코로나19 재수생 가림막 난이도 ytn 순발력 코로나바이러스 종로학원 대표이사 코로나 수준대 변별력 결시자 전문가 집중도 감염증 물수능 [SEP]',\n",
              " '[CLS] 생존자 자살생존자 한국 자살자 유가족 외도 사람들 상처들 황웃는돌씨 통계청 황웃는돌 별자 지지모임 자살사 사망자 자살사별자 교통사고 죄책감 얘깁 결혼식 경제협력개발국가 자살율 특성화 20여년 미국 5배 연예인 친숙 조금씩 38만 자살예방재단 5명 금기시 정치인 9명 한다리 한국사회 72만 자살생존 웹툰 그중 자살유족 survivor weekpick [SEP]',\n",
              " '[CLS] 민원인 공직자 박성일 완주 서원대학교 완주군 정태연 친절도 서비스학 체감친절도 주민접점 강화교육 공무원 직원들 중요성 민원응대 친절 응대 직원 공감 민원 교육 관리 요령 방법 지네 서비스 향상 역량 주제 마인드 스트레스 [SEP]',\n",
              " '[CLS] 온젠티스 파킨슨병 치료제 레보도파 유럽 비알 파킨슨 김정훈 중추신경계 동작 운동동요증상 유럽의약품청 sk케미칼 증후군 독일 영국 [SEP]',\n",
              " '[CLS] 서울 동작구 학년도 숭실대학교 고사장 시험 논술 신분 대학 수학 수험 능력 확인 마스크 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li8oRajbd4p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90371b6c-70eb-493b-c175-c620dbc44897"
      },
      "source": [
        "# 라벨 추출\n",
        "labels = test['label'].values\n",
        "labels"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([47, 10, 21, ...,  4,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvpQ49nEd4p6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1062408-69f0-4df9-8eed-b3aa9d00faf8"
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] rcep 중소기업 fta 인지도 중기중앙회 경쟁력 지원정책 온라인 일본 김태환 전시회 활용방안 정작 [SEP]\n",
            "['[CLS]', 'r', '##ce', '##p', '중', '##소', '##기', '##업', 'ft', '##a', '인', '##지', '##도', '중', '##기', '##중', '##앙', '##회', '경', '##쟁', '##력', '지', '##원', '##정', '##책', '온', '##라', '##인', '일본', '김', '##태', '##환', '전', '##시', '##회', '활', '##용', '##방', '##안', '정', '##작', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI9viuAvd4p_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f07913-7c81-468b-a23e-d92da8340033"
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,    186,  10419,  10410,   9694,  22333,  12310,  26784,\n",
              "        13786,  10113,   9640,  12508,  12092,   9694,  12310,  41693,\n",
              "       119119,  14863,   8885, 119202,  28143,   9706,  14279,  16605,\n",
              "       119254,   9582,  17342,  12030,  23130,   8935,  83616,  51745,\n",
              "         9665,  14040,  14863,   9996,  24974,  42337,  34951,   9670,\n",
              "        38709,    102,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1NKmP0Fd4qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23164a98-2ced-4902-a33f-3ca33c80c7e8"
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIkaYCGbd4qG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1380350-0ce1-49d0-b1b4-ad534ccc4922"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,    186,  10419,  10410,   9694,  22333,  12310,  26784,  13786,\n",
            "         10113,   9640,  12508,  12092,   9694,  12310,  41693, 119119,  14863,\n",
            "          8885, 119202,  28143,   9706,  14279,  16605, 119254,   9582,  17342,\n",
            "         12030,  23130,   8935,  83616,  51745,   9665,  14040,  14863,   9996,\n",
            "         24974,  42337,  34951,   9670,  38709,    102,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(47)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gwdYv1Ad4qK"
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBvpU-Hfgcth"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **MODEL Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heToD1ev0mOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d542791-cc08-4a18-ebb7-ab41528868f6"
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6enIxvt1FB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e36917e-037a-484f-93b9-e55040e4edfa"
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS2MXSiLg5zC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3f782358d6ed404e82526234384fe73d",
            "5a4b42cb188848aebf2b1c05ffc0e8a8",
            "bb9b8504f84946ad85ff2b5ec9bc09ed",
            "dbdbbceaa74e49a08028e74519313f5e",
            "1fec2784340147a58c5a7ff4a28c0965",
            "5edbcdafb3c648329a1ac820fd630071",
            "b52a84f04e494a3b81815ba67965f2f3",
            "dfe2e28797c342e4bd86d61d5023d160",
            "440820427fb244e1a6a3f9509ee9f035",
            "31bd284010fe4fc99dc5a565f661f932",
            "a0429b3af57c4ba685d50e033c62200e",
            "bb7d72ab051f46f896c7df72996906ec",
            "432f11c679c44ff0b1c2d26d50d3259b",
            "bc85d5934b9440ef89fd4cd345ae491e",
            "83f4a6a3fd1540bb86cbe230d68e4e1e",
            "9bfc5bc2aa7248709329627907d259cf"
          ]
        },
        "outputId": "bfe12065-6523-443d-bf8f-84b3a2b5ea52"
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=NUM_LABELS)\n",
        "model.cuda()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f782358d6ed404e82526234384fe73d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "440820427fb244e1a6a3f9509ee9f035",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=58, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdfbLTuWmxk"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 30\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzCHV_ghj7DM"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **MODEL Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-p6pPVXCRe"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJXISnJzCdLM"
      },
      "source": [
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aum0P-dbjOyE"
      },
      "source": [
        "from time import gmtime, strftime\n",
        "START_TIME = strftime(\"%Y_%m_%d_%H_%M_%S\", gmtime())"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muU2kS2GCh4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "10ab8179-ad09-4305-a928-2d989dc4ec43"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "    \n",
        "    PATH = BASE_PATH+\"/bert_news_model_{}.pth\".format(START_TIME)\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    print(\"  Model saved at {}\".format(PATH))\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-68f17714b580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Backward 수행으로 그래디언트 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# 그래디언트 클리핑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGKzE5uXMocG"
      },
      "source": [
        "#**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJu2skuzCANS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3611d79-3d37-46c4-8b08-eb7cd309af78"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=NUM_LABELS)\n",
        "model.cuda()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=85, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BVbl4Zjatzn"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Test Set Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5KHb6RkbHdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e71cb5d-6910-4cfb-90f8-6dc0244d3e5b"
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of    375.    Elapsed: 0:00:07.\n",
            "  Batch   200  of    375.    Elapsed: 0:00:13.\n",
            "  Batch   300  of    375.    Elapsed: 0:00:20.\n",
            "\n",
            "Accuracy: 0.58\n",
            "Test took: 0:00:25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7SzL1IBe1Dm"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "# **NEW topic Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4v_VfEfGQB"
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C12NL1Fvgv4E"
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQezr0tljJlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dfc821d-614f-4a36-8781-85a284d0a40a"
      },
      "source": [
        "logits = test_sentences(['경찰 무력 시위 강압 폭행'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.5553014   1.1636798   4.331775    0.284531    0.701762    0.18182372\n",
            "  -0.81259525 -0.6040593   0.73273855 -0.07076877  0.05800076  1.6265992\n",
            "  -0.6516759  -0.79124063  1.6689017  -1.013213    1.4717002  -0.16425364\n",
            "  -0.93220574 -0.31989643  1.8041921  -0.4293834  -1.014419   -1.1526823\n",
            "  -0.63746774 -1.6706144  -0.03637895  0.14784603  0.76720166 -0.43307778\n",
            "  -0.7251667  -0.48204148 -0.2615093  -0.17751452 -0.7837909  -0.83278006\n",
            "  -1.6937932  -0.64513594 -0.4853816   3.1254256  -0.17023526 -0.5775923\n",
            "   0.06924354  0.65088516 -0.319876   -0.8639546   0.2839826  -0.2693283\n",
            "   0.29786462 -1.0309901  -0.38604105 -0.8095653   0.3269498  -0.04358091\n",
            "  -0.6004411  -0.7257758   0.9699153   0.66252625 -0.15584436  0.01081265\n",
            "  -0.44517967 -0.8007265   0.24600221 -1.0492593   0.28927797 -0.32362634\n",
            "  -0.60572743 -0.59088296 -0.97560203 -0.21741377 -0.13653731 -1.0215555\n",
            "  -0.14815433 -1.2362684  -0.47499362 -0.8426772   0.5446229   0.16645676\n",
            "  -0.9795745  -0.68315876 -0.6824562  -0.5328635  -0.98858774 -1.2208331\n",
            "  -0.6203224 ]]\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}